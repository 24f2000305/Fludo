# ðŸŽ“ Fine-Tuning Guide: Making the CAD Agent Excellent

## Overview
This guide explains how to improve the AI agent's ability to generate complex, working CadQuery code through various fine-tuning and optimization strategies.

---

## ðŸš€ Strategy 1: Context Caching (RECOMMENDED - Start Here)

**Cost**: Almost free (90% cost reduction)  
**Complexity**: Easy  
**Effectiveness**: High

### What is Context Caching?
Gemini 1.5 Pro/Flash supports caching large system prompts. Instead of paying for the full prompt every time, you cache it once and reuse it for 1 hour.

### How to Implement:

```python
import google.generativeai as genai

# Create cached content with your system prompt
cached_content = genai.caching.CachedContent.create(
    model='models/gemini-1.5-flash-8b',
    system_instruction=CADQUERY_SYSTEM_PROMPT,  # Your large system prompt
    ttl=datetime.timedelta(hours=1)  # Cache for 1 hour
)

# Use the cached model
model = genai.GenerativeModel.from_cached_content(cached_content)

# Now every generation uses the cached prompt!
response = model.generate_content("Create a gear with 20 teeth")
```

### Benefits:
- âœ… Huge cost savings (90% reduction on system prompt)
- âœ… Faster responses (prompt already processed)
- âœ… Consistent behavior across sessions
- âœ… No training data needed

### Implementation Steps:
1. Update `app/cad_agent.py` to use caching
2. Cache expires after 1 hour - automatically recreated
3. Perfect for production use

---

## ðŸŽ¯ Strategy 2: Few-Shot Learning (CURRENT APPROACH - Enhance It)

**Cost**: Free  
**Complexity**: Easy  
**Effectiveness**: Medium-High

### What We're Already Doing:
The current system prompt includes examples of correct CadQuery code. This is "few-shot learning."

### How to Improve:

#### A. Add More High-Quality Examples
Create a library of tested, working examples:

```python
CADQUERY_EXAMPLES = """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ“š PROVEN WORKING EXAMPLES LIBRARY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EXAMPLE 1: Parametric Mounting Bracket
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
import cadquery as cq

# Parameters
width = 60
height = 40
thickness = 5
hole_diameter = 6
hole_spacing = 40

result = (cq.Workplane("XY")
    .rect(width, height).extrude(thickness)
    .faces(">Z").workplane()
    .rect(hole_spacing, hole_spacing, forConstruction=True)
    .vertices().hole(hole_diameter)
    .edges("|Z").fillet(2)
)

EXAMPLE 2: Threaded Insert Boss
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
import cadquery as cq

boss_diameter = 12
boss_height = 8
insert_diameter = 6
insert_depth = 6

result = (cq.Workplane("XY")
    .circle(boss_diameter / 2)
    .extrude(boss_height)
    .faces(">Z").workplane()
    .circle(insert_diameter / 2)
    .cutBlind(-insert_depth)
    .faces(">Z").chamfer(0.5)
)

EXAMPLE 3: Complex Gear (20 teeth)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
import cadquery as cq
import math

# Gear parameters
module = 2
teeth = 20
pressure_angle = 20
thickness = 10

pitch_diameter = module * teeth
outer_diameter = pitch_diameter + (2 * module)

result = (cq.Workplane("XY")
    .circle(outer_diameter / 2)
    .extrude(thickness)
    .faces(">Z").workplane()
    .circle(5)  # Center hole
    .cutThruAll()
)

# Add gear teeth (simplified involute approximation)
for i in range(teeth):
    angle = i * 360 / teeth
    tooth = (cq.Workplane("XY")
        .transformed(rotate=(0, 0, angle))
        .moveTo(pitch_diameter / 2 - module, 0)
        .line(module * 2, 0)
        .line(0, thickness)
        .line(-module * 2, 0)
        .close()
        .extrude(1)
    )
    result = result.union(tooth)

EXAMPLE 4: Enclosure with Snap Fits
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
import cadquery as cq

# Enclosure dimensions
length = 100
width = 60
height = 30
wall_thickness = 2

# Main box
result = (cq.Workplane("XY")
    .rect(length, width).extrude(height)
    .faces(">Z").shell(-wall_thickness)
    .edges("|Z").fillet(1)
)

# Add snap fit tabs on sides
tab_width = 8
tab_height = 4
tab_offset = 20

for x in [-length/4, length/4]:
    tab = (cq.Workplane("YZ")
        .workplane(offset=x)
        .rect(tab_width, tab_height)
        .extrude(wall_thickness)
        .translate((0, width/2, height - tab_height/2))
    )
    result = result.union(tab)
"""
```

#### B. Create Domain-Specific Examples
If you're focusing on specific types of parts (mechanical, electronic enclosures, etc.), add targeted examples:

```python
# Add to your system prompt
MECHANICAL_EXAMPLES = """
Robotics Parts Library:
- Servo motor mounts
- Bearing housings
- Shaft couplers
- Gripper fingers
"""

ENCLOSURE_EXAMPLES = """
Electronics Enclosures:
- Raspberry Pi cases
- PCB standoffs
- Cable glands
- Ventilation grids
"""
```

---

## ðŸ§  Strategy 3: Retrieval-Augmented Generation (RAG)

**Cost**: Low (vector DB hosting)  
**Complexity**: Medium  
**Effectiveness**: Very High

### What is RAG?
Instead of cramming everything into the prompt, store a database of examples and retrieve relevant ones based on the user's query.

### Architecture:

```
User Query: "Create a gear"
    â†“
Vector Search: Find similar examples in database
    â†“
Retrieved: Gear examples, involute tooth profiles, etc.
    â†“
Inject into prompt with user query
    â†“
Generate code with relevant context
```

### Implementation:

```python
from langchain.vectorstores import Chroma
from langchain.embeddings import GoogleGenerativeAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter

# 1. Create vector database of CadQuery examples
embeddings = GoogleGenerativeAIEmbeddings(
    model="models/embedding-001",
    google_api_key=os.getenv("GEMINI_API_KEY")
)

# 2. Load your examples
examples = [
    {"code": "...", "description": "Parametric gear", "tags": ["gear", "mechanical"]},
    {"code": "...", "description": "Mounting bracket", "tags": ["bracket", "structural"]},
    # ... more examples
]

# 3. Create vector store
texts = [f"{ex['description']}\n{ex['code']}" for ex in examples]
vectorstore = Chroma.from_texts(texts, embeddings)

# 4. Use in generation
def generate_with_rag(user_prompt):
    # Find relevant examples
    relevant_docs = vectorstore.similarity_search(user_prompt, k=3)
    
    # Build enhanced prompt
    enhanced_prompt = f"""
Relevant examples:
{relevant_docs}

User request: {user_prompt}

Generate CadQuery code following the patterns shown above.
"""
    
    # Generate with Gemini
    model = genai.GenerativeModel('gemini-1.5-flash')
    response = model.generate_content(enhanced_prompt)
    return response.text
```

### Benefits:
- âœ… Unlimited examples (not limited by context window)
- âœ… Only relevant examples used
- âœ… Easily add new examples over time
- âœ… Great for domain-specific applications

---

## ðŸŽ“ Strategy 4: Full Fine-Tuning (ADVANCED)

**Cost**: High ($$$)  
**Complexity**: High  
**Effectiveness**: Highest  

### When to Use:
- You have 1000+ high-quality CadQuery examples
- You need consistent behavior across all queries
- You want the model to deeply understand CadQuery semantics

### Process:

#### Step 1: Create Training Dataset
You need pairs of (input, expected_output):

```jsonl
{"contents": [
  {"role": "user", "parts": [{"text": "Create a 50x40x30mm box"}]},
  {"role": "model", "parts": [{"text": "import cadquery as cq\n\nresult = cq.Workplane(\"XY\").box(50, 40, 30)"}]}
]}
{"contents": [
  {"role": "user", "parts": [{"text": "Create a cylinder with radius 20mm and height 50mm"}]},
  {"role": "model", "parts": [{"text": "import cadquery as cq\n\nresult = cq.Workplane(\"XY\").circle(20).extrude(50)"}]}
]}
...
```

#### Step 2: Use Gemini Fine-Tuning API

```python
import google.generativeai as genai

# Upload training data
training_data = genai.upload_file('cadquery_training.jsonl')

# Create fine-tuning job
operation = genai.create_tuning_job(
    source_model='models/gemini-1.5-flash-001-tuning',
    training_data=training_data,
    tuning_config={
        'epoch_count': 10,
        'batch_size': 4,
        'learning_rate': 0.001,
    }
)

# Wait for completion
model = operation.result()

# Use fine-tuned model
response = model.generate_content("Create a gear with 20 teeth")
```

#### Step 3: Collect Training Data

**Option A: Manual Curation**
- Review successful generations
- Fix broken ones
- Save as training examples

**Option B: Automated Collection**
```python
# Save every successful execution
def save_successful_generation(prompt, code):
    with open('successful_generations.jsonl', 'a') as f:
        entry = {
            "contents": [
                {"role": "user", "parts": [{"text": prompt}]},
                {"role": "model", "parts": [{"text": code}]}
            ]
        }
        f.write(json.dumps(entry) + '\n')

# In your execute endpoint:
if result['success']:
    save_successful_generation(user_prompt, code)
```

**Option C: Synthetic Data Generation**
Use GPT-4 or Claude to generate training pairs:
```python
# Use Claude/GPT-4 to create variations
prompts = [
    "Create a box",
    "Make a cylinder", 
    "Design a bracket",
    # ...
]

for prompt in prompts:
    # Generate with GPT-4
    code = generate_with_gpt4(prompt)
    # Verify it works
    if validate_cadquery(code):
        save_training_pair(prompt, code)
```

---

## ðŸ”„ Strategy 5: Reinforcement Learning from Human Feedback (RLHF)

**Cost**: Medium  
**Complexity**: Very High  
**Effectiveness**: Extremely High (but time-intensive)

### Concept:
Users rate generated code as good/bad, and the model learns from feedback.

### Implementation:

```python
# 1. Add rating UI to your app
class CodeGeneration:
    def __init__(self, prompt, code):
        self.prompt = prompt
        self.code = code
        self.rating = None
        self.feedback = None

# 2. Collect feedback
@app.post("/api/rate_generation")
async def rate_generation(request: Request):
    body = await request.json()
    
    # Save to database
    db.save({
        "prompt": body['prompt'],
        "code": body['code'],
        "rating": body['rating'],  # 1-5 stars
        "works": body['executes_successfully'],
        "feedback": body['user_comments']
    })

# 3. Periodically retrain on highly-rated examples
def create_training_set():
    # Get 5-star examples
    examples = db.query("SELECT * FROM generations WHERE rating >= 4")
    
    # Format for fine-tuning
    return format_training_data(examples)
```

---

## ðŸ“Š Strategy 6: Ensemble Approach

**Cost**: Medium  
**Complexity**: Medium  
**Effectiveness**: High

### Use Multiple Models:

```python
async def generate_cadquery_ensemble(prompt):
    # Generate with multiple models
    results = await asyncio.gather(
        generate_with_gemini_flash(prompt),
        generate_with_gemini_pro(prompt),
        generate_with_claude(prompt),  # If you have access
    )
    
    # Test all results
    working_results = []
    for code in results:
        if validate_cadquery_code(code)['valid']:
            working_results.append(code)
    
    if not working_results:
        # Fall back to auto-fix
        return auto_fix_code(results[0])
    
    # Return the simplest working solution
    return min(working_results, key=lambda x: len(x))
```

---

## ðŸŽ¯ RECOMMENDED IMPLEMENTATION PLAN

### Phase 1: Quick Wins (This Week)
1. âœ… **Implement Context Caching** - Save 90% on API costs
2. âœ… **Expand Few-Shot Examples** - Add 20 more proven examples
3. âœ… **Add Domain-Specific Examples** - Focus on your use cases

### Phase 2: Build Infrastructure (Next 2 Weeks)
1. **Set up RAG system** - Vector database with 100+ examples
2. **Auto-save successful generations** - Build training dataset
3. **Add user rating system** - Collect quality feedback

### Phase 3: Advanced (1-2 Months)
1. **Fine-tune on collected data** - Use 1000+ examples
2. **Implement RLHF pipeline** - Learn from user feedback
3. **Deploy ensemble system** - Multiple models for reliability

---

## ðŸ’° Cost Comparison

| Strategy | Setup Cost | Runtime Cost | Time Investment |
|----------|-----------|--------------|-----------------|
| Context Caching | $0 | 90% reduction | 1 hour |
| Few-Shot Learning | $0 | $0 | 2-4 hours |
| RAG | $10-50/mo | +$5-10 per 1000 queries | 1 week |
| Fine-Tuning | $100-500 | $0.02-0.10 per query | 2-4 weeks |
| RLHF | $500+ | Varies | 1-3 months |
| Ensemble | $0 | 3x generation cost | 1 week |

---

## ðŸš€ START HERE: Quick Implementation

Let me create a file with context caching implementation you can use right away:

```python
# app/cad_agent_cached.py
import google.generativeai as genai
import datetime
import os

_cached_content = None
_cache_expiry = None

def get_cached_model():
    global _cached_content, _cache_expiry
    
    # Check if cache expired
    now = datetime.datetime.now()
    if _cached_content is None or (_cache_expiry and now > _cache_expiry):
        # Create new cached content
        _cached_content = genai.caching.CachedContent.create(
            model='models/gemini-1.5-flash-8b',
            system_instruction=CADQUERY_SYSTEM_PROMPT,
            ttl=datetime.timedelta(hours=1)
        )
        _cache_expiry = now + datetime.timedelta(hours=1)
    
    return genai.GenerativeModel.from_cached_content(_cached_content)

# Use it like this:
def generate_cadquery_code(prompt: str):
    model = get_cached_model()  # Uses cached prompt!
    response = model.generate_content(prompt)
    return response.text
```

---

## ðŸ“ˆ Measuring Success

Track these metrics to measure improvement:

```python
class GenerationMetrics:
    total_generations: int
    successful_executions: int
    avg_code_length: int
    avg_generation_time: float
    user_satisfaction_score: float
    
    @property
    def success_rate(self):
        return self.successful_executions / self.total_generations

# Target goals:
# - Success rate > 95%
# - Avg generation time < 2 seconds
# - User satisfaction > 4.5/5
```

---

## ðŸŽ“ Learning Resources

- **CadQuery Documentation**: https://cadquery.readthedocs.io/
- **Gemini Tuning Guide**: https://ai.google.dev/docs/model_tuning_guidance
- **Context Caching**: https://ai.google.dev/docs/caching
- **RAG Tutorial**: https://python.langchain.com/docs/use_cases/question_answering/

---

## âœ… Next Steps

1. Read this guide thoroughly
2. Start with Context Caching (biggest ROI)
3. Expand your few-shot examples library
4. Set up analytics to measure improvement
5. Gradually implement RAG and fine-tuning

Let me know which strategy you want to implement first, and I'll help you build it! ðŸš€
